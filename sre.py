import os
import numpy as np

bitsA = 8
bitsW = 2
n_layers = 8

compress_kernel_matrix = False
compress_input_vector = True
compute_dot_production = True

class CrossbarSubarray():
    def __init__(self, sa_size, ou_size, scale, memory):
        self.wvg = WordlineVectorGenerator(sa_size, ou_size, memory)
        self.sa_size = sa_size
        self.ou_size = ou_size
        self.state = np.zeros((sa_size, sa_size), dtype=np.int)
        self.out_reg = np.zeros((sa_size), dtype=np.int)
        self.height = sa_size
        self.width = sa_size
        self.cur_scale = 0
        self.scale = scale
        self.memory = memory
        self.indices_reserved = [[]] * (sa_size // ou_size)
        self.indices_removed = [[]] * (sa_size // ou_size)
        self.index_first = -1
        self.index_last = -1
        self.n_ou_cols = 0
        self.halt = True
        self.n_cycles = 0
        self.n_muls = 0

    def set_indices(self, indices_reserved, indices_removed):
        max_height = 0
        for i in range(len(indices_reserved)):
            if len(indices_reserved[i]) > 0:
                if self.index_first == -1 or self.index_last == -1:
                    assert(self.index_first == self.index_last)
                    self.index_first = indices_reserved[i][0]
                    self.index_last = indices_reserved[i][-1]
                else:
                    if indices_reserved[i][0] < self.index_first:
                        self.index_first = indices_reserved[i][0]
                    if indices_reserved[i][-1] > self.index_last:
                        self.index_last = indices_reserved[i][-1]
            if max_height < len(indices_reserved[i]):
                max_height = len(indices_reserved[i])
        assert(self.height == max_height)
        self.indices_reserved = indices_reserved
        self.indices_removed = indices_removed
    
    def get_indices(self):
        return self.indices_reserved, self.indices_removed

    def deploy_matrix_weight(self, input_matrix):
        self.height = input_matrix.shape[0]
        self.width = input_matrix.shape[1]
        self.state[:self.height, :self.width] = input_matrix.copy()
        self.n_ou_cols = (self.width - 1) // self.ou_size + 1
        self.wvg.set_n_ou_cols(self.n_ou_cols)

    if compress_kernel_matrix:
        def fetch_bit_vector(self, ou_col, bit_pos):
            return self.wvg.iib.fetch_input_vector(
                self.indices_reserved[ou_col])[:, self.memory.n_v_bits-1-bit_pos]
    else:
        def fetch_bit_vector(self, bit_pos):
            return self.wvg.iib.fetch_input_vector()[:, self.memory.n_v_bits-1-bit_pos]

    if compress_kernel_matrix:
        def set_memory_address(self, batch, offset):
            self.wvg.iib.set_memory_address(batch, offset)
    else:
        def set_memory_address(self, batch, offset, beg, end):
            self.wvg.iib.set_memory_address(batch, offset, beg, end)

    def dump_output_register(self):
        out = self.out_reg
        self.out_reg = np.zeros((self.sa_size), dtype=np.int)
        return out

    def generate_wordline_activation_vector(self):
        if compress_kernel_matrix:
            self.wvg.generate_wordline_activation_vector(self.indices_reserved)
        else:
            self.wvg.generate_wordline_activation_vector()

    def compute_mvm_cycle(self):
        wav, indices, ou_col, bit_pos, all_dumped = self.wvg.get_wordline_activation_vector()
        if any(wav):
            self.n_muls += len(indices) * min(self.ou_size, self.width - ou_col * self.ou_size)
            if compute_dot_production:
                if compress_kernel_matrix:
                    vec = self.fetch_bit_vector(ou_col, bit_pos)[indices].T
                else:
                    vec = self.fetch_bit_vector(bit_pos)[indices].T
                ou = self.state[indices, ou_col*self.ou_size:(ou_col+1)*self.ou_size]
                self.out_reg[ou_col*self.ou_size:(ou_col+1)*self.ou_size] += np.dot(vec, ou) * self.cur_scale
        if all_dumped:
            if ou_col == self.n_ou_cols - 1:
                if bit_pos == self.memory.n_v_bits - 1:
                    self.halt = True
                else:
                    self.cur_scale *= self.scale

    def compute_mvm(self):
        self.halt = False
        self.cur_scale = 1
        self.generate_wordline_activation_vector()
        while not self.halt:
            self.compute_mvm_cycle()
            self.n_cycles += 1
        self.wvg.reset_states()

    def print_statistic_result(self):
        print("  Number of Valid Cycles: " + str(self.n_cycles))
        print("  Number of Operated Multiplications: " + str(self.n_muls))
        print("  Wordline Vector Generator:")
        self.wvg.print_statistic_result()
        print("  Input Index Buffer:")
        self.wvg.iib.print_statistic_result()

class WordlineVectorGenerator():
    def __init__(self, sa_size, ou_size, memory):
        self.sa_size = sa_size
        self.ou_size = ou_size
        self.act_beg = 0
        self.len_vectors = []
        self.iib = InputIndexBuffer(memory)
        self.n_ou_cols = 0
        self.ou_col = 0
        self.bit_pos = 0
        self.decoded_indices = []
        self.n_decoded_wavs = 0
        self.n_adds = 0
        self.n_generated_wavs = 0

    def set_n_ou_cols(self, n_ou_cols):
        self.n_ou_cols = n_ou_cols

    if compress_input_vector:
        if compress_kernel_matrix:
            def generate_wordline_activation_vector(self, indices_reserved):
                for i in range(len(indices_reserved)):
                    self.len_vectors.append(len(indices_reserved[i]))
                self.iib.generate_wordline_activation_vector(indices_reserved)
                self.decode_indices()
        else:
            def generate_wordline_activation_vector(self):
                self.iib.generate_wordline_activation_vector()
                self.decode_indices()

        def decode_indices(self):
            if compress_kernel_matrix:
                encoded_indices = self.iib.get_wordline_activation_vector(self.ou_col, self.bit_pos)
            else:
                encoded_indices = self.iib.get_wordline_activation_vector(self.bit_pos)
            if encoded_indices:
                self.n_decoded_wavs += 1
                self.n_adds += len(encoded_indices) - 1
                self.decoded_indices = [encoded_indices[0]]
                for i in range(1, len(encoded_indices)):
                    self.decoded_indices.append(
                        encoded_indices[i] + self.decoded_indices[i-1])
            else:
                self.decoded_indices = []

    def switch_indices(self):
        self.act_beg = 0
        self.ou_col += 1
        if self.ou_col >= self.n_ou_cols:
            self.ou_col = 0
            self.bit_pos += 1
        if compress_input_vector:
            self.decode_indices()

    def get_wordline_activation_vector(self):
        if compress_kernel_matrix:
            assert(self.len_vectors[self.ou_col])
            wav = np.zeros((self.len_vectors[self.ou_col], 1), np.int)
        else:
            wav = np.zeros((self.sa_size, 1), np.int)
        self.n_generated_wavs += 1
        if compress_input_vector:
            indices = self.decoded_indices[self.act_beg:self.act_beg+self.ou_size]
        else:
            indices = range(self.act_beg, self.act_beg+self.ou_size)
        wav[indices] = 1
        self.act_beg += self.ou_size
        ou_col = self.ou_col
        bit_pos = self.bit_pos
        if self.act_beg >= len(self.decoded_indices):
            self.act_beg = 0
            self.switch_indices()
            all_dumped = True
        else:
            all_dumped = False
        return wav, indices, ou_col, bit_pos, all_dumped

    def reset_states(self):
        self.act_beg = 0
        self.len_vectors = []
        self.ou_col = 0
        self.bit_pos = 0
        self.decoded_indices = []
        self.iib.clear_buffer()

    def print_statistic_result(self):
        print("    Number of Decoded WAVs: " + str(self.n_decoded_wavs))
        print("    Number of Operated Additions: " + str(self.n_adds))
        print("    Number of Generated WAVs: " + str(self.n_generated_wavs))

class InputIndexBuffer():
    def __init__(self, memory):
        self.buffer = []
        self.memory = memory
        self.batch = 0
        self.offset = 0
        self.in_reg = None
        self.n_fetched_vectors = 0
        self.n_fetched_values = 0
        self.n_scanned_values = 0

    if compress_kernel_matrix:
        def set_memory_address(self, batch, offset):
            self.batch = batch
            self.offset = offset
    else:
        def set_memory_address(self, batch, offset, beg, end):
            self.batch = batch
            self.offset = offset
            self.beg = beg
            self.end = end

    if compress_kernel_matrix:
        def fetch_input_vector(self, indices_reserved):
            if self.in_reg is None:
                self.in_reg = self.memory.fetch_input_vector(
                    self.batch, self.offset, indices_reserved)
                self.n_fetched_vectors += 1
                self.n_fetched_values += self.in_reg.shape[0] * self.in_reg.shape[1]
            return self.in_reg
    else:
        def fetch_input_vector(self):
            if self.in_reg is None:
                self.in_reg = self.memory.fetch_input_vector(
                    self.batch, self.offset, self.beg, self.end)
                self.n_fetched_vectors += 1
                self.n_fetched_values += self.in_reg.shape[0] * self.in_reg.shape[1]
            return self.in_reg

    if compress_kernel_matrix:
        def exploit_vector_sparsity(self, vector):
            self.n_scanned_values += vector.shape[0] * vector.shape[1]
            self.buffer.append([])
            for i in range(vector.shape[1]):
                self.buffer[-1].append([])
                k = 0
                for j in range(vector.shape[0]):
                    value = vector[j, vector.shape[1]-1-i]
                    if value == 1 or value == -1:
                        self.buffer[-1][i].append(j-k)
                        k = j
    else:
        def exploit_vector_sparsity(self, vector):
            self.n_scanned_values += vector.shape[0] * vector.shape[1]
            for i in range(vector.shape[1]):
                self.buffer.append([])
                k = 0
                for j in range(vector.shape[0]):
                    value = vector[j, vector.shape[1]-1-i]
                    if value == 1 or value == -1:
                        self.buffer[i].append(j-k)
                        k = j

    if compress_kernel_matrix:
        def generate_wordline_activation_vector(self, indices_reserved):
            for i in range(len(indices_reserved)):
                self.exploit_vector_sparsity(
                    self.fetch_input_vector(indices_reserved[i]))
    else:
        def generate_wordline_activation_vector(self):
            self.exploit_vector_sparsity(self.fetch_input_vector())

    if compress_kernel_matrix:
        def get_wordline_activation_vector(self, ou_col, bit_pos):
            if ou_col >= len(self.buffer) or bit_pos >= len(self.buffer[ou_col]):
                return []
            else:
                return self.buffer[ou_col][bit_pos]
    else:
        def get_wordline_activation_vector(self, bit_pos):
            if bit_pos >= len(self.buffer):
                return []
            else:
                return self.buffer[bit_pos]

    def clear_buffer(self):
        self.buffer = []
        self.in_reg = None

    def print_statistic_result(self):
        print("    Number of Fetched Vectors: " + str(self.n_fetched_vectors))
        print("    Number of Fetched Values: " + str(self.n_fetched_values))
        print("    Number of Scanned Values: " + str(self.n_scanned_values))

class Memory():
    def __init__(self, n_bits):
        self.buffer = []
        self.n_bits = n_bits
        self.n_v_bits = n_bits - 1
        assert(self.n_v_bits > 0)

    def store_input_vector(self, vectors):
        self.buffer = vectors

    if compress_kernel_matrix:
        def fetch_input_vector(self, batch, offset, indices):
            return self.buffer[batch, indices, offset*self.n_v_bits:(offset+1)*self.n_v_bits]
    else:
        def fetch_input_vector(self, batch, offset, beg, end):
            return self.buffer[batch, beg:end, offset*self.n_v_bits:(offset+1)*self.n_v_bits]

class SparseReRamEngine():
    def __init__(self, sa_size=128, w_res=2, adc_res=5, ou_size=16, n_w_bits=2, n_a_bits=8, scale=2, n_replica=0):
        self.subarrays = []
        self.wvgs = []
        self.sa_size = sa_size
        self.w_res = w_res
        self.adc_res = adc_res
        self.ou_size = ou_size
        self.n_sa_r = 0
        self.n_sa_c = 0
        self.n_w_bits = n_w_bits
        self.n_a_bits = n_a_bits
        self.scale = scale
        self.n_replica = n_replica
        self.memory = Memory(n_a_bits)
        assert(self.sa_size % self.ou_size == 0)

    def adjust_weight_resolution(self, input_matrix, original_matrix_shape):
        assert(input_matrix.shape[1] == self.w_res * original_matrix_shape[3])
        in_matrix = input_matrix.copy()
        for i in range(self.w_res - 1):
            in_matrix[:, ::self.w_res] += in_matrix[:, i+1::self.w_res]
        in_matrix = in_matrix[:, ::self.w_res]
        return in_matrix

    def deploy_matrix_weight(self, input_matrix, original_matrix_shape):
        if self.subarrays:
            print("warning: already deployed")
            self.subarrays = []

        in_matrix = self.adjust_weight_resolution(input_matrix, original_matrix_shape)
        if compress_kernel_matrix:
            in_matrices, index_removed_row, index_reserved_row = self.compress_matrix_by_ou_row(in_matrix)

            max_len = 0
            for i in range(len(index_reserved_row)):
                for j in range((len(index_reserved_row[i]))):
                    this_len = (len(index_reserved_row[i][j]) - 1) * self.sa_size + len(index_reserved_row[i][j][-1])
                    if max_len < this_len:
                        max_len = this_len
            self.n_sa_r = (max_len - 1) // self.sa_size + 1
            self.n_sa_c = len(index_reserved_row)

            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    all_empty = True
                    ms = []
                    heights = []
                    for k in range(len(index_reserved_row[j])):
                        ms.append(in_matrices[j*self.sa_size//self.ou_size+k][i*self.sa_size:(i+1)*self.sa_size, :])
                        heights.append(ms[-1].shape[0])
                        if ms[-1].shape[0] > 0:
                            all_empty = False
                    if all_empty:
                        self.subarrays[-1].append(None)
                    else:
                        max_heights = max(heights)
                        for k in range(len(index_reserved_row[j])):
                            if ms[k].shape[0] < max_heights:
                                ms[k] = np.vstack((ms[k], np.zeros((max_heights-ms[k].shape[0], ms[k].shape[1]))))
                        m = np.hstack(ms)
                        sa = CrossbarSubarray(self.sa_size, self.ou_size, self.scale, self.memory)
                        sa.deploy_matrix_weight(m)
                        target_indices_reserved = []
                        target_indices_removed = []
                        for k in range(len(index_reserved_row[j])):
                            target_indices_reserved.append(index_reserved_row[j][k][i])
                            target_indices_removed.append(index_removed_row[j][k][i])
                        sa.set_indices(target_indices_reserved, target_indices_removed)
                        self.subarrays[-1].append(sa)
        else:
            self.n_sa_r = (in_matrix.shape[0] - 1) // self.sa_size + 1
            self.n_sa_c = (in_matrix.shape[1] - 1) // self.sa_size + 1
            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    part = in_matrix[i*self.sa_size:(i+1)*self.sa_size, j*self.sa_size:(j+1)*self.sa_size]
                    sa = CrossbarSubarray(self.sa_size, self.ou_size, self.scale, self.memory)
                    sa.deploy_matrix_weight(part)
                    self.subarrays[i].append(sa)

        """
        k_hei = original_matrix_shape[0]
        k_wid = original_matrix_shape[1]
        in_ch = original_matrix_shape[2]

        if self.mode == 'conventional':
            self.n_sa_r = (in_shape[0] - 1) // self.sa_size + 1
            self.n_sa_c = (in_shape[1] - 1) // self.sa_size + 1
            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    part = in_matrix[i*self.sa_size:(i+1)*self.sa_size, j*self.sa_size:(j+1)*self.sa_size]
                    sa = CrossbarSubarray(self.sa_size, self.ou_size)
                    sa.deploy_matrix_weight(part)
                    self.subarrays[i].append(sa)
        elif self.mode == 'novel':
            n_sa_r_per_ch = (in_ch - 1) // self.sa_size + 1
            self.n_sa_r = k_hei * k_wid * n_sa_r_per_ch
            self.n_sa_c = (in_shape[1] - 1) // self.sa_size + 1
            self.state = np.zeros((self.n_sa_r, self.n_sa_c, self.sa_size, self.sa_size), dtype=np.int)
            lower_bound_r = 0
            for i in range(self.n_sa_r):
                if i % n_sa_r_per_ch == n_sa_r_per_ch - 1:
                    higher_bound_r = lower_bound_r + in_ch % self.sa_size
                else:
                    higher_bound_r = lower_bound_r + self.sa_size
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    part = in_matrix[lower_bound_r:higher_bound_r, j*self.sa_size:(j+1)*self.sa_size]
                    sa = CrossbarSubarray(self.sa_size, self.ou_size)
                    sa.deploy_matrix_weight(part)
                    self.subarrays[i].append(sa)
                lower_bound_r = higher_bound_r
        else:
            print("error: unknown deploy mode")
        """

        self.n_sa_r_replicated = self.n_sa_r * (self.n_replica + 1)
        for _ in range(self.n_replica):
            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    source_sa = self.subarrays[i][j]
                    sa = CrossbarSubarray(self.sa_size, self.ou_size, self.scale, self.memory)
                    sa.deploy_matrix_weight(source_sa.state[:source_sa.height, :source_sa.width])
                    if compress_kernel_matrix:
                        sa.set_indices(*source_sa.get_indices())
                    self.subarrays[-1].append(sa)

    def compress_matrix_by_ou_row(self, matrix):
        height = matrix.shape[0]
        width = matrix.shape[1]
        n_ou_cols = (width - 1) // self.ou_size + 1
        matrices = []
        for i in range(n_ou_cols):
            matrices.append(matrix[:, i*self.ou_size:(i+1)*self.ou_size])
        index_removed_row = []
        index_reserved_row = []
        for i in range(n_ou_cols):
            if i * self.ou_size % self.sa_size == 0:
                index_removed_row.append([])
                index_reserved_row.append([])
            index_removed_row[-1].append([])
            index_reserved_row[-1].append([])
            index_removed_row[-1][-1].append([])
            index_reserved_row[-1][-1].append([])
            for j in range(height):
                if (matrices[i][j, :] == 0).all():
                    index_removed_row[-1][-1][-1].append(j)
                else:
                    index_reserved_row[-1][-1][-1].append(j)
                    if len(index_reserved_row[-1][-1][-1]) % self.sa_size == 0:
                        index_reserved_row[-1][-1].append([])
                        index_removed_row[-1][-1].append([])
            index_reserved_row_total = []
            for j in range(len(index_reserved_row[-1][-1])):
                index_reserved_row_total.extend(index_reserved_row[-1][-1][j])
            matrices[i] = matrices[i][index_reserved_row_total, :]
        return matrices, index_removed_row, index_reserved_row

    def do_inference(self, input_feature_map):
        n_batches = input_feature_map.shape[0]
        n_input_vector = input_feature_map.shape[2] // self.n_a_bits
        n_passes = (n_input_vector - 1) // (self.n_replica + 1) + 1
        res = []
        self.memory.store_input_vector(input_feature_map)
        for b in range(n_batches):
            for p in range(n_passes):
                n_sliced_vec = min(self.n_replica + 1, n_input_vector - p * (self.n_replica + 1))
                for k in range(n_sliced_vec):
                    for i in range(self.n_sa_r):
                        for j in range(self.n_sa_c):
                            if compress_kernel_matrix:
                                self.subarrays[k*self.n_sa_r+i][j].set_memory_address(
                                    b, p*(self.n_replica+1)+k)
                            else:
                                self.subarrays[k*self.n_sa_r+i][j].set_memory_address(
                                    b, p*(self.n_replica+1)+k, i*self.sa_size, (i+1)*self.sa_size)
                for i in range(self.n_sa_r_replicated):
                    for j in range(self.n_sa_c):
                        self.subarrays[i][j].compute_mvm()
                        if compute_dot_production:
                            res.append(self.subarrays[i][j].dump_output_register())
        if compute_dot_production:
            ans = []
            for b in range(n_batches):
                ans.append([])
                for p in range(n_passes):
                    for _ in range(self.n_replica + 1):
                        vec = []
                        for i in range(self.n_sa_r):
                            vec.append([])
                            for j in range(self.n_sa_c):
                                vec[-1].extend(res.pop(0))
                        ans[-1].append(np.sum(np.array(vec), 0))
            kernel_matrix_width = self.sa_size * (self.n_sa_c - 1) + self.subarrays[0][-1].width
            ans = np.array(ans)[:, :n_input_vector, :kernel_matrix_width]
            return ans
    
    def print_statistic_result(self):
        for i in range(self.n_sa_r_replicated):
            for j in range(self.n_sa_c):
                print("Subarray " + str(i) + ", " + str(j) + ":")
                self.subarrays[i][j].print_statistic_result()

def load_transformed_matrix(filename):
    return np.load(filename).astype(np.int)

def simulate_sparsity_exploitation():
    input_path = './layer_record/'

    network_shape = np.loadtxt('./NetWork.csv', dtype=np.int, delimiter=',')
    w_shape = network_shape[:, 2:6]
    w_shape = w_shape[:, [1, 2, 0, 3]]

    #for i in range(n_layers):
    i = 0
    input_file_name = 'signed_input_layer' + str(i) + '.npy'
    weight_file_name = 'weight_layer' + str(i) + '.npy'

    transformed_weight = load_transformed_matrix(input_path + weight_file_name)
    sre = SparseReRamEngine(ou_size=16, n_w_bits=bitsW, n_a_bits=bitsA, n_replica=3)
    sre.deploy_matrix_weight(transformed_weight, w_shape[i])
    sre1 = SparseReRamEngine(ou_size=2, n_w_bits=bitsW, n_a_bits=bitsA, n_replica=3)
    sre1.deploy_matrix_weight(transformed_weight, w_shape[i])

    transformed_activation = load_transformed_matrix(input_path + input_file_name)

    if compute_dot_production:
        ans = sre.do_inference(transformed_activation[:1])
        ans1 = sre1.do_inference(transformed_activation[:1])
        assert((ans == ans1).all())
        print(ans)
    else:
        sre.do_inference(transformed_activation[:1])
        sre1.do_inference(transformed_activation[:1])

    print("SRE0:")
    sre.print_statistic_result()
    print("SRE1:")
    sre1.print_statistic_result()

def main():
    simulate_sparsity_exploitation()

if __name__ == "__main__":
    main()
