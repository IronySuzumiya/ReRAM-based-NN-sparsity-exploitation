import os
import numpy as np
import multiprocessing as mp

bitsA = 8
bitsW = 2
n_layers = 8

class CrossbarSubarray():
    def __init__(self, sa_size, ou_size, a_scale, memory,
        compress_kernel_matrix, compress_input_vector, compute_dot_production):
        self.wvg = WordlineVectorGenerator(
            sa_size, ou_size, memory,
            compress_kernel_matrix,
            compress_input_vector)
        self.sa_size = sa_size
        self.ou_size = ou_size
        self.state = np.zeros((sa_size, sa_size), dtype=np.int)
        self.out_reg = np.zeros((sa_size), dtype=np.int)
        self.height = sa_size
        self.width = sa_size
        self.a_scale = a_scale
        self.memory = memory
        self.indices_reserved = [[]] * (sa_size // ou_size)
        self.indices_removed = [[]] * (sa_size // ou_size)
        self.index_first = -1
        self.index_last = -1
        self.n_ou_cols = 0
        self.halt = True
        self.n_cycles = 0
        self.n_muls = 0
        self.compress_kernel_matrix = compress_kernel_matrix
        self.compress_input_vector = compress_input_vector
        self.compute_dot_production = compute_dot_production

    def set_indices(self, indices_reserved, indices_removed):
        max_height = 0
        for i in range(len(indices_reserved)):
            if len(indices_reserved[i]) > 0:
                if self.index_first == -1 or self.index_last == -1:
                    assert(self.index_first == self.index_last)
                    self.index_first = indices_reserved[i][0]
                    self.index_last = indices_reserved[i][-1]
                else:
                    if indices_reserved[i][0] < self.index_first:
                        self.index_first = indices_reserved[i][0]
                    if indices_reserved[i][-1] > self.index_last:
                        self.index_last = indices_reserved[i][-1]
            if max_height < len(indices_reserved[i]):
                max_height = len(indices_reserved[i])
        assert(self.height == max_height)
        self.indices_reserved = indices_reserved
        self.indices_removed = indices_removed
    
    def get_indices(self):
        return self.indices_reserved, self.indices_removed

    def deploy_matrix_weight(self, input_matrix):
        self.height = input_matrix.shape[0]
        self.width = input_matrix.shape[1]
        self.state[:self.height, :self.width] = input_matrix.copy()
        self.n_ou_cols = (self.width - 1) // self.ou_size + 1
        self.wvg.set_n_ou_cols(self.n_ou_cols)

    def fetch_bit_vector(self, *args):
        if self.compress_kernel_matrix:
            ou_col, bit_pos = args
            return self.wvg.iib.fetch_input_vector(
                self.indices_reserved[ou_col])[:, self.memory.n_v_bits-1-bit_pos]
        else:
            bit_pos = args[0]
            return self.wvg.iib.fetch_input_vector()[:, self.memory.n_v_bits-1-bit_pos]

    def set_memory_address(self, batch, offset, *args):
        if self.compress_kernel_matrix:
            self.wvg.iib.set_memory_address(batch, offset)
        else:
            beg, end = args
            self.wvg.iib.set_memory_address(batch, offset, beg, end)

    def dump_output_register(self):
        out = self.out_reg
        self.out_reg = np.zeros((self.sa_size), dtype=np.int)
        return out

    def generate_wordline_activation_vector(self):
        if self.compress_kernel_matrix:
            self.wvg.set_len_input_vectors(self.indices_reserved)
            if self.compress_input_vector:
                self.wvg.generate_wordline_activation_vector(self.indices_reserved)
            else:
                self.wvg.generate_wordline_activation_vector()
        else:
            self.wvg.set_len_input_vector(self.height)
            if self.compress_input_vector:
                self.wvg.generate_wordline_activation_vector()

    def compute_mvm_cycle(self):
        wav, indices, ou_col, bit_pos, halt = self.wvg.get_wordline_activation_vector()
        if halt:
            self.halt = halt
        else:
            assert(any(wav))
            self.n_muls += len(indices) * min(self.ou_size, self.width - ou_col * self.ou_size)
            if self.compute_dot_production:
                if self.compress_kernel_matrix:
                    vec = self.fetch_bit_vector(ou_col, bit_pos)[indices].T
                else:
                    vec = self.fetch_bit_vector(bit_pos)[indices].T
                ou = self.state[indices, ou_col*self.ou_size:(ou_col+1)*self.ou_size]
                self.out_reg[ou_col*self.ou_size:(ou_col+1)*self.ou_size] += np.dot(vec, ou) * (self.a_scale ** bit_pos)

    def compute_mvm(self):
        self.halt = False
        self.generate_wordline_activation_vector()
        while not self.halt:
            self.compute_mvm_cycle()
            self.n_cycles += 1
        self.wvg.reset_states()

    def get_statistic_result(self):
        res = "  Number of Activated Cycles: " + str(self.n_cycles) + "\n"
        res += "  Number of Operated Multiplications: " + str(self.n_muls) + "\n"
        res += "  Wordline Vector Generator:\n" + self.wvg.get_statistic_result()
        res += "  Input Index Buffer:\n" + self.wvg.iib.get_statistic_result()
        return res

def compute_mvm_wrapper(cls_instance):
    cls_instance.compute_mvm()

class WordlineVectorGenerator():
    def __init__(self, sa_size, ou_size, memory,
        compress_kernel_matrix, compress_input_vector):
        self.sa_size = sa_size
        self.ou_size = ou_size
        self.act_beg = 0
        self.len_vector = 0
        self.len_vectors = []
        self.memory = memory
        self.iib = InputIndexBuffer(memory, compress_kernel_matrix)
        self.n_ou_cols = 0
        self.ou_col = 0
        self.bit_pos = 0
        self.decoded_indices = []
        self.n_decoded_wavs = 0
        self.n_adds = 0
        self.n_generated_wavs = 0
        self.compress_kernel_matrix = compress_kernel_matrix
        self.compress_input_vector = compress_input_vector

    def set_n_ou_cols(self, n_ou_cols):
        self.n_ou_cols = n_ou_cols

    def set_len_input_vector(self, len_vector):
        self.len_vector = len_vector

    def set_len_input_vectors(self, indices_reserved):
        for i in range(len(indices_reserved)):
            self.len_vectors.append(len(indices_reserved[i]))

    def generate_wordline_activation_vector(self, *args):
        if self.compress_input_vector:
            self.iib.generate_wordline_activation_vector(*args)
            self.decode_indices()
            while not self.decoded_indices and self.bit_pos < self.memory.n_v_bits:
                self.switch_indices()
        elif self.compress_kernel_matrix:
            while self.len_vectors[self.ou_col] == 0 and self.bit_pos < self.memory.n_v_bits:
                self.switch_indices()

    def decode_indices(self):
        if self.compress_kernel_matrix:
            encoded_indices = self.iib.get_wordline_activation_vector(self.ou_col, self.bit_pos)
        else:
            encoded_indices = self.iib.get_wordline_activation_vector(self.bit_pos)
        if encoded_indices:
            self.n_decoded_wavs += 1
            self.n_adds += len(encoded_indices) - 1
            self.decoded_indices = [encoded_indices[0]]
            for i in range(1, len(encoded_indices)):
                self.decoded_indices.append(
                    encoded_indices[i] + self.decoded_indices[i-1])
        else:
            self.decoded_indices = []

    def switch_indices(self):
        self.act_beg = 0
        self.ou_col += 1
        if self.ou_col >= self.n_ou_cols:
            self.ou_col = 0
            self.bit_pos += 1
        if self.compress_input_vector:
            self.decode_indices()

    def get_wordline_activation_vector(self):
        if self.bit_pos >= self.memory.n_v_bits:
            return [], [], self.ou_col, self.bit_pos, True
        if self.compress_kernel_matrix:
            wav = np.zeros((self.len_vectors[self.ou_col], 1), np.int)
        else:
            wav = np.zeros((self.len_vector, 1), np.int)
        self.n_generated_wavs += 1
        if self.compress_input_vector:
            indices = self.decoded_indices[self.act_beg:self.act_beg+self.ou_size]
        else:
            indices = range(self.act_beg, min(self.act_beg+self.ou_size, wav.shape[0]))
        wav[indices] = 1
        self.act_beg += self.ou_size
        ou_col = self.ou_col
        bit_pos = self.bit_pos
        if (self.compress_input_vector and self.act_beg >= len(self.decoded_indices)) \
            or (not self.compress_input_vector and self.act_beg >= wav.shape[0]):
            self.act_beg = 0
            self.switch_indices()
            if self.compress_input_vector:
                while not self.decoded_indices and self.bit_pos < self.memory.n_v_bits:
                    self.switch_indices()
            elif self.compress_kernel_matrix:
                while self.len_vectors[self.ou_col] == 0 and self.bit_pos < self.memory.n_v_bits:
                    self.switch_indices()
        return wav, indices, ou_col, bit_pos, False

    def reset_states(self):
        self.act_beg = 0
        self.len_vector = 0
        self.len_vectors = []
        self.ou_col = 0
        self.bit_pos = 0
        self.decoded_indices = []
        self.iib.clear_buffer()

    def get_statistic_result(self):
        res = "    Number of Decoded WAVs: " + str(self.n_decoded_wavs) + "\n"
        res += "    Number of Operated Additions: " + str(self.n_adds) + "\n"
        res += "    Number of Generated WAVs: " + str(self.n_generated_wavs) + "\n"
        return res

class InputIndexBuffer():
    def __init__(self, memory, compress_kernel_matrix):
        self.buffer = []
        self.memory = memory
        self.batch = 0
        self.offset = 0
        self.n_fetched_vectors = 0
        self.n_fetched_values = 0
        self.n_scanned_values = 0
        self.compress_kernel_matrix = compress_kernel_matrix
    
    def set_memory_address(self, batch, offset, *args):
        self.batch = batch
        self.offset = offset
        if not self.compress_kernel_matrix:
            self.beg, self.end = args
    
    def fetch_input_vector(self, *args):
        if self.compress_kernel_matrix:
            indices_reserved = args[0]
            vec = self.memory.fetch_input_vector(
                self.batch, self.offset, indices_reserved)
        else:
            vec = self.memory.fetch_input_vector(
                self.batch, self.offset, self.beg, self.end)
        self.n_fetched_vectors += 1
        self.n_fetched_values += vec.shape[0] * vec.shape[1]
        return vec

    def exploit_vector_sparsity(self, vector):
        self.n_scanned_values += vector.shape[0] * vector.shape[1]
        if self.compress_kernel_matrix:
            self.buffer.append([])
        for i in range(vector.shape[1]):
            if self.compress_kernel_matrix:
                sub_buffer = self.buffer[-1]
            else:
                sub_buffer = self.buffer
            sub_buffer.append([])
            k = 0
            for j in range(vector.shape[0]):
                value = vector[j, vector.shape[1]-1-i]
                if value == 1 or value == -1:
                    sub_buffer[i].append(j-k)
                    k = j

    def generate_wordline_activation_vector(self, *args):
        if self.compress_kernel_matrix:
            indices_reserved = args[0]
            for i in range(len(indices_reserved)):
                self.exploit_vector_sparsity(
                    self.fetch_input_vector(indices_reserved[i]))
        else:
            self.exploit_vector_sparsity(self.fetch_input_vector())

    
    def get_wordline_activation_vector(self, *args):
        if self.compress_kernel_matrix:
            ou_col, bit_pos = args
            sub_buffer = self.buffer[ou_col]
        else:
            bit_pos = args[0]
            sub_buffer = self.buffer
        if (self.compress_kernel_matrix and ou_col >= len(self.buffer)) \
            or bit_pos >= len(sub_buffer):
            return []
        else:
            return sub_buffer[bit_pos]

    def clear_buffer(self):
        self.buffer = []

    def get_statistic_result(self):
        res = "    Number of Fetched Vectors: " + str(self.n_fetched_vectors) + "\n"
        res += "    Number of Fetched Values: " + str(self.n_fetched_values) + "\n"
        res += "    Number of Scanned Values: " + str(self.n_scanned_values) + "\n"
        return res

class Memory():
    def __init__(self, n_bits, compress_kernel_matrix):
        self.buffer = []
        self.n_bits = n_bits
        self.n_v_bits = n_bits - 1
        assert(self.n_v_bits > 0)
        self.compress_kernel_matrix = compress_kernel_matrix

    def store_input_vector(self, vectors):
        self.buffer = vectors

    def fetch_input_vector(self, batch, offset, *args):
        if self.compress_kernel_matrix:
            indices = args[0]
            return self.buffer[batch, indices, offset*self.n_v_bits:(offset+1)*self.n_v_bits]
        else:
            beg, end = args
            return self.buffer[batch, beg:end, offset*self.n_v_bits:(offset+1)*self.n_v_bits]

class SparseReRamEngine():
    def __init__(self, sa_size=128, w_res=2, adc_res=5, ou_size=16,
        n_w_bits=2, n_a_bits=8, a_scale=2, w_scale=2, n_replica=0,
        compress_kernel_matrix=False,
        compress_input_vector=False,
        compute_dot_production=True):
        self.subarrays = []
        self.wvgs = []
        self.sa_size = sa_size
        self.w_res = w_res
        self.adc_res = adc_res # not used for now
        self.ou_size = ou_size
        self.n_sa_r = 0
        self.n_sa_c = 0
        self.n_w_bits = n_w_bits
        self.n_a_bits = n_a_bits
        self.a_scale = a_scale
        self.w_scale = w_scale
        self.n_replica = n_replica
        self.compress_kernel_matrix = compress_kernel_matrix
        self.compress_input_vector = compress_input_vector
        self.compute_dot_production = compute_dot_production
        self.memory = Memory(n_a_bits, compress_kernel_matrix)
        assert(self.sa_size % self.ou_size == 0)
        assert(self.sa_size % (self.n_w_bits // self.w_res) == 0)
        assert(self.n_w_bits % self.w_res == 0)

    def deploy_matrix_weight(self, input_matrix):
        if self.subarrays:
            print("warning: already deployed")
            self.subarrays = []

        if self.compress_kernel_matrix:
            in_matrices, index_removed_row, index_reserved_row = self.compress_matrix_by_ou_row(input_matrix)

            max_len = 0
            for i in range(len(index_reserved_row)):
                for j in range((len(index_reserved_row[i]))):
                    this_len = (len(index_reserved_row[i][j]) - 1) * self.sa_size + len(index_reserved_row[i][j][-1])
                    if max_len < this_len:
                        max_len = this_len
            self.n_sa_r = (max_len - 1) // self.sa_size + 1
            self.n_sa_c = len(index_reserved_row)

            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    all_empty = True
                    ms = []
                    heights = []
                    for k in range(len(index_reserved_row[j])):
                        ms.append(in_matrices[j*self.sa_size//self.ou_size+k][i*self.sa_size:(i+1)*self.sa_size, :])
                        heights.append(ms[-1].shape[0])
                        if ms[-1].shape[0] > 0:
                            all_empty = False
                    if all_empty:
                        self.subarrays[-1].append(None)
                    else:
                        max_heights = max(heights)
                        for k in range(len(index_reserved_row[j])):
                            if ms[k].shape[0] < max_heights:
                                ms[k] = np.vstack((ms[k], np.zeros((max_heights-ms[k].shape[0], ms[k].shape[1]))))
                        m = np.hstack(ms)
                        sa = CrossbarSubarray(self.sa_size, self.ou_size, self.a_scale, self.memory,
                            self.compress_kernel_matrix, self.compress_input_vector, self.compute_dot_production)
                        sa.deploy_matrix_weight(m)
                        target_indices_reserved = []
                        target_indices_removed = []
                        for k in range(len(index_reserved_row[j])):
                            if i < len(index_reserved_row[j][k]):
                                target_indices_reserved.append(index_reserved_row[j][k][i])
                            else:
                                target_indices_reserved.append([])
                            if i < len(index_removed_row[j][k]):
                                target_indices_removed.append(index_removed_row[j][k][i])
                            else:
                                target_indices_removed.append([])
                        sa.set_indices(target_indices_reserved, target_indices_removed)
                        self.subarrays[-1].append(sa)
        else:
            self.n_sa_r = (input_matrix.shape[0] - 1) // self.sa_size + 1
            self.n_sa_c = (input_matrix.shape[1] - 1) // self.sa_size + 1
            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    part = input_matrix[i*self.sa_size:(i+1)*self.sa_size, j*self.sa_size:(j+1)*self.sa_size]
                    sa = CrossbarSubarray(self.sa_size, self.ou_size, self.a_scale, self.memory,
                        self.compress_kernel_matrix, self.compress_input_vector, self.compute_dot_production)
                    sa.deploy_matrix_weight(part)
                    self.subarrays[i].append(sa)

        self.n_sa_r_replicated = self.n_sa_r * (self.n_replica + 1)
        for _ in range(self.n_replica):
            for i in range(self.n_sa_r):
                self.subarrays.append([])
                for j in range(self.n_sa_c):
                    source_sa = self.subarrays[i][j]
                    sa = CrossbarSubarray(self.sa_size, self.ou_size, self.a_scale, self.memory,
                        self.compress_kernel_matrix, self.compress_input_vector, self.compute_dot_production)
                    sa.deploy_matrix_weight(source_sa.state[:source_sa.height, :source_sa.width])
                    if self.compress_kernel_matrix:
                        sa.set_indices(*source_sa.get_indices())
                    self.subarrays[-1].append(sa)

    def compress_matrix_by_ou_row(self, matrix):
        height = matrix.shape[0]
        width = matrix.shape[1]
        n_ou_cols = (width - 1) // self.ou_size + 1
        matrices = []
        for i in range(n_ou_cols):
            matrices.append(matrix[:, i*self.ou_size:(i+1)*self.ou_size])
        index_removed_row = []
        index_reserved_row = []
        for i in range(n_ou_cols):
            if i * self.ou_size % self.sa_size == 0:
                index_removed_row.append([])
                index_reserved_row.append([])
            index_removed_row[-1].append([])
            index_reserved_row[-1].append([])
            index_removed_row[-1][-1].append([])
            index_reserved_row[-1][-1].append([])
            for j in range(height):
                if (matrices[i][j, :] == 0).all():
                    index_removed_row[-1][-1][-1].append(j)
                else:
                    index_reserved_row[-1][-1][-1].append(j)
                    if len(index_reserved_row[-1][-1][-1]) % self.sa_size == 0:
                        index_reserved_row[-1][-1].append([])
                        index_removed_row[-1][-1].append([])
            index_reserved_row_total = []
            for j in range(len(index_reserved_row[-1][-1])):
                index_reserved_row_total.extend(index_reserved_row[-1][-1][j])
            matrices[i] = matrices[i][index_reserved_row_total, :]
        return matrices, index_removed_row, index_reserved_row

    def do_inference(self, input_feature_map):
        n_batches = input_feature_map.shape[0]
        n_input_vectors = input_feature_map.shape[2] // self.n_a_bits
        n_passes = (n_input_vectors - 1) // (self.n_replica + 1) + 1
        w_space_ratio = self.n_w_bits // self.w_res
        res = []
        self.memory.store_input_vector(input_feature_map)
        for b in range(n_batches):
            for p in range(n_passes):
                n_sliced_vec = min(self.n_replica + 1, n_input_vectors - p * (self.n_replica + 1))
                for k in range(n_sliced_vec):
                    for i in range(self.n_sa_r):
                        for j in range(self.n_sa_c):
                            if self.compress_kernel_matrix:
                                self.subarrays[k*self.n_sa_r+i][j].set_memory_address(
                                    b, p*(self.n_replica+1)+k)
                            else:
                                self.subarrays[k*self.n_sa_r+i][j].set_memory_address(
                                    b, p*(self.n_replica+1)+k, i*self.sa_size, (i+1)*self.sa_size)
                process_results = []
                pool = mp.Pool(processes=self.n_sa_r_replicated*self.n_sa_c)
                for i in range(self.n_sa_r_replicated):
                    for j in range(self.n_sa_c):
                        process_results.append(
                            pool.apply_async(compute_mvm_wrapper, (self.subarrays[i][j], )))
                pool.close()
                pool.join()
                for p_res in process_results:
                    print(p_res.get())
                if self.compute_dot_production:
                    for i in range(self.n_sa_r_replicated):
                        for j in range(self.n_sa_c):
                            res.append(self.subarrays[i][j].dump_output_register())
        if self.compute_dot_production:
            ans = []
            a_base = 1.0 / (self.a_scale ** (self.n_a_bits - 1))
            w_base = 1.0 / (self.w_scale ** (self.n_w_bits - 1))
            for _ in range(n_batches):
                ans.append([])
                for _ in range(n_input_vectors):
                    vec = []
                    for _ in range(self.n_sa_r):
                        vec.append([])
                        for _ in range(self.n_sa_c):
                            vec[-1].extend(res.pop(0))
                    vec = np.sum(np.array(vec), 0)
                    vs = []
                    for i in range(vec.shape[0]//w_space_ratio):
                        v = vec[i*w_space_ratio:(i+1)*w_space_ratio]
                        value = 0
                        for j in range(w_space_ratio):
                            value += v[w_space_ratio-1-j] * ((self.w_scale ** self.w_res) ** j)
                        vs.append(value * a_base * w_base)
                    ans[-1].append(vs)
            kernel_matrix_width = self.sa_size * (self.n_sa_c - 1) + self.subarrays[0][-1].width
            ans = np.array(ans)[:, :n_input_vectors, :kernel_matrix_width]
            return ans
    
    def get_statistic_result(self):
        res = "Mode Configuration:\n"
        if self.compress_input_vector:
            res += "  Input Vector Compression\n"
        if self.compress_kernel_matrix:
            res += "  Kernel Matrix Compression\n"
        if not self.compress_input_vector and not self.compress_kernel_matrix:
            res += "  No Compression\n"
        for i in range(self.n_sa_r_replicated):
            for j in range(self.n_sa_c):
                res += "Subarray " + str(i) + ", " + str(j) + ":\n"
                res += self.subarrays[i][j].get_statistic_result() + "\n"
        return res

def save_output_vector(vector, filename):
    np.save(filename, vector)

def load_transformed_matrix(filename):
    return np.load(filename).astype(np.int)

def simulate_sparsity_exploitation_subf(i, compute_dot_production):
    input_path = './layer_record/'
    output_path = './layer_record/'
    input_file_name = 'signed_input_layer' + str(i) + '_part0.npy'
    weight_file_name = 'signed_weight_layer' + str(i) + '.npy'

    transformed_weight = load_transformed_matrix(input_path + weight_file_name)

    SREs = []

    SREs.append(SparseReRamEngine(ou_size=4, n_replica=0,
        compute_dot_production=compute_dot_production))
    SREs.append(SparseReRamEngine(ou_size=4, n_replica=0,
        compress_input_vector=True, compute_dot_production=compute_dot_production))
    SREs.append(SparseReRamEngine(ou_size=4, n_replica=0,
        compress_kernel_matrix=True, compute_dot_production=compute_dot_production))
    SREs.append(SparseReRamEngine(ou_size=4, n_replica=0,
        compress_kernel_matrix=True, compress_input_vector=True,
        compute_dot_production=compute_dot_production))
    
    for j in range(len(SREs)):
        SREs[j].deploy_matrix_weight(transformed_weight)

    transformed_activation = load_transformed_matrix(input_path + input_file_name)

    ans = []

    ans.append(SREs[0].do_inference(transformed_activation))
    
    for j in range(1, len(SREs)):
        ans.append(SREs[j].do_inference(transformed_activation))
        if compute_dot_production:
            if not (ans[0] == ans[j]).all():
                with open('error_log.txt', 'w') as f:
                    f.write("Results are inconsistent: Layer" + str(i) + " SRE" + str(j))
                exit(-1)

    if compute_dot_production:
        output_file_name = 'layer' + str(i) + '_output.npy'
        save_output_vector(ans[0], output_path + output_file_name)

    statistic_result_file_name = 'layer' + str(i) + '_statistic_result.txt'
    with open(output_path + statistic_result_file_name, 'w') as f:
        for j in range(len(SREs)):
            f.write("SRE" + str(j) + ":\n")
            f.write(SREs[j].get_statistic_result())

def simulate_sparsity_exploitation():
    network_shape = np.loadtxt('./NetWork.csv', dtype=np.int, delimiter=',')
    w_shape = network_shape[:, 2:6]
    w_shape = w_shape[:, [1, 2, 0, 3]]

    compute_dot_production = True

    for i in range(n_layers):
        simulate_sparsity_exploitation_subf(i, compute_dot_production)

def main():
    simulate_sparsity_exploitation()

if __name__ == "__main__":
    main()
